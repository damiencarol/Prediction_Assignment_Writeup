---
title: "Prediction Assignment Writeup"
author: "Damien Carol"
date: "October 31, 2016"
output: html_document
---

The goal of this project is to predict the manner in which people did the exercise. Is it good or not?

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

## Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. 
In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.
They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har .

## Data loading

We will use the 2 data sets. But we want to remove many columns as there are not present in
validation dataset and are mainly null value in the train dataset.

```{r,  cache=TRUE}
# get the data (train)
pmltrain <- read.csv("pml-training.csv", stringsAsFactors=FALSE)
# this line could be use to get only one row by session in order to subsample data (very useful)
#pmltrain <- subset(pmltrain, new_window == 'yes')
pmltrain$classe <- as.factor(pmltrain$classe)
```

At this point we will remove few group of variables that are empty.

```{r}
# remove the first line (ID of the line)
pmltrain <- pmltrain[,-1]
pmltrain <- pmltrain[,-grep("user_name|raw_timestamp_part_1|raw_timestamp_part_2|cvtd_timestamp|new_window|num_window",
                             colnames(pmltrain))]
# first group of missing data in validation data set
pmltrain <- pmltrain[,-grep("kurtosis_roll_belt|kurtosis_picth_belt|kurtosis_yaw_belt|skewness_roll_belt|skewness_roll_belt.1|skewness_yaw_belt|max_roll_belt|max_picth_belt|max_yaw_belt|$
                             colnames(pmltrain))]

# second group of missing data
pmltrain <- pmltrain[,-grep("var_accel_arm|avg_roll_arm|stddev_roll_arm|var_roll_arm|avg_pitch_arm|stddev_pitch_arm|var_pitch_arm|avg_yaw_arm|stddev_yaw_arm|var_yaw_arm",
                             colnames(pmltrain))]
# another group of missing data
pmltrain <- pmltrain[,-grep("kurtosis_roll_arm|kurtosis_picth_arm|kurtosis_yaw_arm|skewness_roll_arm|skewness_pitch_arm|skewness_yaw_arm|max_roll_arm|max_picth_arm|max_yaw_arm|min_roll_a$
                             colnames(pmltrain))]

# another group of missing data
pmltrain <- pmltrain[,-grep("kurtosis_roll_dumbbell|kurtosis_picth_dumbbell|kurtosis_yaw_dumbbell|skewness_roll_dumbbell|skewness_pitch_dumbbell|skewness_yaw_dumbbell|max_roll_dumbbell|m$
                             colnames(pmltrain))]


# another group of missing data
pmltrain <- pmltrain[,-grep("var_accel_dumbbell|avg_roll_dumbbell|stddev_roll_dumbbell|var_roll_dumbbell|avg_pitch_dumbbell|stddev_pitch_dumbbell|var_pitch_dumbbell|avg_yaw_dumbbell|stdd$
                             colnames(pmltrain))]
# another group of missing data
pmltrain <- pmltrain[,-grep("kurtosis_roll_forearm|kurtosis_picth_forearm|kurtosis_yaw_forearm|skewness_roll_forearm|skewness_pitch_forearm|skewness_yaw_forearm|max_roll_forearm|max_pict$
                             colnames(pmltrain))]
```
At this point we have a good entry point for machine learning part.

### Machine learning part

First we initialize our library.

```{r}
library(caret)
```

Splitting the data set into train/test parts.

```{r}
inTrain = createDataPartition(pmltrain$classe, p=0.7, list=FALSE)
training = pmltrain[inTrain,]
testing = pmltrain[-inTrain,]
```

Applying the model

```{r}
modFit = train(classe ~ ., data=training, method="rf")
```

Now, we can test it on test part
```{r}
pred = predict(modFit,newdata = testing)
```

We have now a complete model with some results. We can show a confusion matrix

```{r}
confusionMatrix(pred,testing$classe)
```

This give this output:

```
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1673    9    0    0    0
         B    1 1124    2    0    1
         C    0    2 1021   11    3
         D    0    2    3  950    5
         E    0    2    0    3 1073

Overall Statistics

               Accuracy : 0.9925
                 95% CI : (0.99, 0.9946)
    No Information Rate : 0.2845
    P-Value [Acc > NIR] : < 2.2e-16

                  Kappa : 0.9905
 Mcnemar's Test P-Value : NA

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9994   0.9868   0.9951   0.9855   0.9917
Specificity            0.9979   0.9992   0.9967   0.9980   0.9990
Pos Pred Value         0.9946   0.9965   0.9846   0.9896   0.9954
Neg Pred Value         0.9998   0.9968   0.9990   0.9972   0.9981
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2843   0.1910   0.1735   0.1614   0.1823
Detection Prevalence   0.2858   0.1917   0.1762   0.1631   0.1832
Balanced Accuracy      0.9986   0.9930   0.9959   0.9917   0.9953
```
We have accuracy > 99.2%, that enought to answer the quiz

# Validation

Now we want to prepare data for validation. We will just load the validation data and apply the same model.

```{r}
# get the data (validation)
pmltesting <- read.csv("pml-testing.csv", stringsAsFactors=FALSE)
pmltesting <- pmltesting[,names(pmltesting) %in% names(pmltrain)]
predValid = predict(modFit,newdata = pmltesting)
# output the results
predValid
```
This give result (answer of the quiz): 
```
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
```
